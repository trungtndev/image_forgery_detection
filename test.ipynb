{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-08T18:39:06.498233Z",
     "start_time": "2024-10-08T18:39:06.478688Z"
    }
   },
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from src.datamodule.datamodule import ImageForgeryDatamMdule\n",
    "from timm.models.swin_transformer import SwinTransformer\n",
    "from timm.models.layers import SelectAdaptivePool2d\n",
    "import timm\n",
    "from torch import nn\n",
    "import torch_dct as dct\n",
    "from src.model.cnn_gru import HybridCNNGRU"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T18:39:06.513856Z",
     "start_time": "2024-10-08T18:39:06.498233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# state_dict = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True).state_dict()\n",
    "# model = SwinTransformer(        \n",
    "#             drop_rate=0.9,\n",
    "#             proj_drop_rate=0.9,\n",
    "#             attn_drop_rate=0.9,\n",
    "#             drop_path_rate=0.9,\n",
    "#         )\n",
    "# model.load_state_dict(state_dict)\n",
    "# model.head = nn.Identity()\n",
    "# model(image).shape"
   ],
   "id": "c4b322a4dfe55cea",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T18:39:06.529482Z",
     "start_time": "2024-10-08T18:39:06.513856Z"
    }
   },
   "cell_type": "code",
   "source": "image = torch.rand(1, 3, 224, 224)",
   "id": "308d3d70bd1556a4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T18:39:06.797535Z",
     "start_time": "2024-10-08T18:39:06.529482Z"
    }
   },
   "cell_type": "code",
   "source": "HybridCNNGRU(d_model=256, hidden_size=512, input_channels=3)(image).shape",
   "id": "b5dbbe5e2b5de8cd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 225, 256])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
