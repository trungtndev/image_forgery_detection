{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-10T16:00:42.928668Z",
     "start_time": "2024-10-10T16:00:42.507574Z"
    }
   },
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_dct import dct_2d\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from src.datamodule.datamodule import ImageForgeryDatamMdule\n",
    "from timm.models.swin_transformer import SwinTransformer\n",
    "from src.model.cnn_gru import HybridCNNGRU\n",
    "from timm.models.layers import SelectAdaptivePool2d, ClassifierHead\n",
    "import timm\n",
    "from torch import nn\n",
    "import torch_dct as dct\n",
    "from src.lit_model import LitModel"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trung\\miniconda3\\envs\\image_forgery\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:32:39.812451Z",
     "start_time": "2024-10-10T12:32:37.346770Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 7, 7, 768]) torch.Size([3, 7, 7, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0133,  0.0979],\n",
       "        [-0.0203,  0.1181],\n",
       "        [ 0.0270,  0.1115]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "",
   "id": "c4b322a4dfe55cea",
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T16:07:17.607228Z",
     "start_time": "2024-10-10T16:07:17.591523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = \"data/CASIA1/train/real/Sp_S_NNN_T_txt0074_txt0074_0074.jpg\"\n",
    "image = Image.open(path)\n",
    "image = transforms.ToTensor()(image)"
   ],
   "id": "4b495c120ff53ddc",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T16:33:22.713078Z",
     "start_time": "2024-10-10T16:33:22.691270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ImageToFrequency(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageToFrequency, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = dct_2d(x, norm='ortho')\n",
    "        x = torch.fft.fftshift(x)\n",
    "        x = log_magnitude(x)\n",
    "        return x\n",
    "ImageToFrequency()(image)\n",
    "# "
   ],
   "id": "389b1bd8cbe987cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0691, 0.0061, 0.0662,  ..., 0.1001, 0.0278, 0.0577],\n",
       "         [0.0860, 0.0255, 0.0283,  ..., 0.0084, 0.1299, 0.0077],\n",
       "         [0.0926, 0.0440, 0.0039,  ..., 0.0711, 0.0630, 0.2013],\n",
       "         ...,\n",
       "         [0.0842, 0.0222, 0.0596,  ..., 0.1134, 0.2486, 0.0858],\n",
       "         [0.1391, 0.0089, 0.0585,  ..., 0.0901, 0.1656, 0.0137],\n",
       "         [0.1132, 0.0247, 0.0711,  ..., 0.1052, 0.0367, 0.0718]],\n",
       "\n",
       "        [[0.0726, 0.0144, 0.0729,  ..., 0.1183, 0.0442, 0.0704],\n",
       "         [0.0946, 0.0397, 0.0200,  ..., 0.0183, 0.0976, 0.0074],\n",
       "         [0.0771, 0.0517, 0.0227,  ..., 0.0767, 0.0786, 0.2117],\n",
       "         ...,\n",
       "         [0.0907, 0.0255, 0.0538,  ..., 0.1245, 0.2924, 0.1038],\n",
       "         [0.1560, 0.0338, 0.0172,  ..., 0.0677, 0.1638, 0.0455],\n",
       "         [0.1156, 0.0237, 0.0479,  ..., 0.0980, 0.0249, 0.0650]],\n",
       "\n",
       "        [[0.0687, 0.0192, 0.0740,  ..., 0.1097, 0.0347, 0.0627],\n",
       "         [0.0966, 0.0315, 0.0258,  ..., 0.0217, 0.1093, 0.0038],\n",
       "         [0.0850, 0.0522, 0.0215,  ..., 0.0767, 0.0751, 0.2143],\n",
       "         ...,\n",
       "         [0.0845, 0.0257, 0.0620,  ..., 0.1108, 0.2851, 0.0943],\n",
       "         [0.1450, 0.0350, 0.0343,  ..., 0.0758, 0.1653, 0.0394],\n",
       "         [0.1053, 0.0210, 0.0580,  ..., 0.1058, 0.0300, 0.0685]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T16:11:57.877226Z",
     "start_time": "2024-10-10T16:11:57.861137Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "bbd90dffef833774",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1061)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T16:11:24.428556Z",
     "start_time": "2024-10-10T16:11:24.415578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def log_magnitude(f_shift):\n",
    "    return torch.log(1 + torch.abs(f_shift))"
   ],
   "id": "234003b997cdf5e",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:25:40.854658Z",
     "start_time": "2024-10-10T12:25:40.823407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "B, W, H, D = 2, 8, 8, 768  # B: batch size, W: chiều rộng, H: chiều cao, D: số chiều đặc trưng\n",
    "C = 10  # Số lớp (classes)\n",
    "output = torch.randn(B, W, H, D)  # Đầu ra từ mô hình CNN hoặc tương tự\n",
    "\n",
    "# Áp dụng Global Average Pooling trên chiều không gian (W, H)\n",
    "pooled_output = output.mean(dim=(1, 2))  # Kích thước: (B, D)\n",
    "print(\"Pooled output:\", pooled_output.shape)\n",
    "# Chuyển thành logits (số lớp)\n",
    "linear = nn.Linear(D, C)\n",
    "logits = linear(pooled_output)  # Kích thước: (B, C)\n",
    "\n",
    "# Tính cross entropy loss\n",
    "target = torch.randint(0, C, (B,))  # Ground truth labels\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss = loss_fn(logits, target)\n",
    "\n",
    "print(\"Loss:\", loss.item())\n"
   ],
   "id": "f8e7c36b793e8003",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled output: torch.Size([2, 768])\n",
      "Loss: 2.2533135414123535\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:26:36.734721Z",
     "start_time": "2024-10-10T12:26:36.719099Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "664a18bc5a20ebdf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 6.1461e-02,  1.7132e-01, -4.3081e-02,  ...,  1.8428e-01,\n",
       "            7.9201e-02,  7.7000e-03]],\n",
       "\n",
       "         [[-7.3590e-02,  3.6203e-02,  3.1155e-02,  ..., -1.8917e-01,\n",
       "           -6.0701e-02, -1.1432e-02]],\n",
       "\n",
       "         [[-1.5933e-01, -1.1345e-01,  1.8945e-04,  ...,  7.2752e-02,\n",
       "            1.4967e-01,  1.9428e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.1533e-01, -9.6979e-02, -2.8492e-02,  ...,  9.7934e-03,\n",
       "           -7.2704e-02,  4.2504e-02]],\n",
       "\n",
       "         [[-9.3216e-02, -1.5313e-01, -7.4550e-02,  ...,  5.9874e-02,\n",
       "           -2.6313e-02,  3.4397e-01]],\n",
       "\n",
       "         [[ 1.0297e-01,  5.2828e-02,  2.3151e-01,  ...,  2.2125e-02,\n",
       "           -1.2867e-01,  3.0936e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 5.8546e-02, -1.3710e-02, -1.9255e-01,  ...,  4.8425e-02,\n",
       "           -8.8405e-02,  5.4689e-02]],\n",
       "\n",
       "         [[-1.3192e-01,  8.8368e-02, -1.4156e-01,  ..., -1.5053e-01,\n",
       "           -3.6285e-02,  1.3985e-01]],\n",
       "\n",
       "         [[ 3.4798e-02, -2.0436e-02,  2.9200e-02,  ..., -8.3135e-02,\n",
       "            6.5053e-03, -9.5515e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-7.1736e-02, -8.9937e-02, -8.4593e-02,  ..., -2.5837e-02,\n",
       "           -2.4385e-02, -4.2717e-02]],\n",
       "\n",
       "         [[-6.5155e-02, -2.7794e-01, -1.8503e-01,  ...,  1.0515e-01,\n",
       "           -8.9068e-02,  8.0077e-02]],\n",
       "\n",
       "         [[-6.7781e-02,  1.0529e-01, -1.4259e-01,  ...,  3.5550e-02,\n",
       "            4.3580e-02, -2.5840e-01]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:26:52.980414Z",
     "start_time": "2024-10-10T12:26:52.949161Z"
    }
   },
   "cell_type": "code",
   "source": "pooled_output",
   "id": "5744f99c6d070200",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1690, -0.0028, -0.0676,  ..., -0.0259,  0.0784,  0.0794],\n",
       "        [-0.1619,  0.1977, -0.1895,  ..., -0.0112, -0.2003,  0.0325]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "25468e876865fac2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:27:01.530492200Z",
     "start_time": "2024-10-10T07:15:19.087019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x1 = torch.rand(1, 14, 14, 224)\n",
    "x2 = torch.rand(1, 14, 14, 512)"
   ],
   "id": "308d3d70bd1556a4",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:27:01.530492200Z",
     "start_time": "2024-10-10T07:15:19.394732Z"
    }
   },
   "cell_type": "code",
   "source": "(att(x1, x2)).shape",
   "id": "63d35b52a43ce873",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 14, 128])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:27:01.530492200Z",
     "start_time": "2024-10-10T07:15:19.710140Z"
    }
   },
   "cell_type": "code",
   "source": "ClassifierHead(in_features=14, num_classes=2)(att(x1, x2))",
   "id": "b5dbbe5e2b5de8cd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1777,  0.0030]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:27:01.530492200Z",
     "start_time": "2024-10-10T07:15:22.352134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tem = torch.rand(1, 2, 10)\n",
    "torch.nn.Softmax(dim=1)(tem)"
   ],
   "id": "10ebb48943eb454b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5063, 0.4341, 0.5391, 0.3359, 0.4139, 0.5473, 0.4205, 0.4878,\n",
       "          0.5356, 0.4875],\n",
       "         [0.4937, 0.5659, 0.4609, 0.6641, 0.5861, 0.4527, 0.5795, 0.5122,\n",
       "          0.4644, 0.5125]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:27:01.530492200Z",
     "start_time": "2024-10-10T09:59:25.234262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(CNN, self).__init__()\n",
    "        self.module = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.GELU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=1, padding=1),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.GELU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2, padding=1),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.GELU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=1),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.GELU(),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.module(x)\n",
    "\n",
    "\n",
    "CNN(3)(image).shape"
   ],
   "id": "2ca855730e86a713",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 112, 112])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:27:01.530492200Z",
     "start_time": "2024-10-10T07:26:00.112386Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2d89fc2c24f67eae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 109, 109])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
