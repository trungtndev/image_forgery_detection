{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-10T12:56:57.375445Z",
     "start_time": "2024-10-10T12:56:57.347563Z"
    }
   },
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from src.model.fusion import AttentionFusionModule\n",
    "from src.datamodule.datamodule import ImageForgeryDatamMdule\n",
    "from timm.models.swin_transformer import SwinTransformer\n",
    "from src.model.cnn_gru import HybridCNNGRU\n",
    "from timm.models.layers import SelectAdaptivePool2d, ClassifierHead\n",
    "import timm\n",
    "from torch import nn\n",
    "import torch_dct as dct\n",
    "from src.lit_model import LitModel"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:57:15.758036Z",
     "start_time": "2024-10-10T12:57:15.711015Z"
    }
   },
   "cell_type": "code",
   "source": "image = torch.rand(3, 3, 224, 224)",
   "id": "61c07d20f11ecf10",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:32:39.812451Z",
     "start_time": "2024-10-10T12:32:37.346770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LitModel(\n",
    "    num_classes=2,\n",
    "    d_model=512,\n",
    "    pretrain=True,\n",
    "    requires_grad=True,\n",
    "    drop_rate=0.0,\n",
    "    proj_drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    drop_path_rate=0.0,\n",
    "    hidden_size=512,\n",
    "    image_size=224,\n",
    "    patch_size=7,\n",
    "\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-6,\n",
    "    patience=5,\n",
    ").forward(image)"
   ],
   "id": "c4b322a4dfe55cea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 7, 7, 768]) torch.Size([3, 7, 7, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0133,  0.0979],\n",
       "        [-0.0203,  0.1181],\n",
       "        [ 0.0270,  0.1115]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T13:10:40.961002Z",
     "start_time": "2024-10-10T13:10:40.866971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(CNN, self).__init__()\n",
    "        self.module = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.GELU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2, padding=1),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.GELU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2, padding=1),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.GELU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2, padding=1),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.GELU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=1, padding=0),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.module(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "CNN(3)(image).shape"
   ],
   "id": "389b1bd8cbe987cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 28, 28])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T13:10:29.810785Z",
     "start_time": "2024-10-10T13:10:29.779536Z"
    }
   },
   "cell_type": "code",
   "source": "28 / 7",
   "id": "bbd90dffef833774",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:25:40.854658Z",
     "start_time": "2024-10-10T12:25:40.823407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "B, W, H, D = 2, 8, 8, 768  # B: batch size, W: chiều rộng, H: chiều cao, D: số chiều đặc trưng\n",
    "C = 10  # Số lớp (classes)\n",
    "output = torch.randn(B, W, H, D)  # Đầu ra từ mô hình CNN hoặc tương tự\n",
    "\n",
    "# Áp dụng Global Average Pooling trên chiều không gian (W, H)\n",
    "pooled_output = output.mean(dim=(1, 2))  # Kích thước: (B, D)\n",
    "print(\"Pooled output:\", pooled_output.shape)\n",
    "# Chuyển thành logits (số lớp)\n",
    "linear = nn.Linear(D, C)\n",
    "logits = linear(pooled_output)  # Kích thước: (B, C)\n",
    "\n",
    "# Tính cross entropy loss\n",
    "target = torch.randint(0, C, (B,))  # Ground truth labels\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss = loss_fn(logits, target)\n",
    "\n",
    "print(\"Loss:\", loss.item())\n"
   ],
   "id": "f8e7c36b793e8003",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled output: torch.Size([2, 768])\n",
      "Loss: 2.2533135414123535\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:26:36.734721Z",
     "start_time": "2024-10-10T12:26:36.719099Z"
    }
   },
   "cell_type": "code",
   "source": "nn.Poo(kernel_size=(8, 8))(output)",
   "id": "664a18bc5a20ebdf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 6.1461e-02,  1.7132e-01, -4.3081e-02,  ...,  1.8428e-01,\n",
       "            7.9201e-02,  7.7000e-03]],\n",
       "\n",
       "         [[-7.3590e-02,  3.6203e-02,  3.1155e-02,  ..., -1.8917e-01,\n",
       "           -6.0701e-02, -1.1432e-02]],\n",
       "\n",
       "         [[-1.5933e-01, -1.1345e-01,  1.8945e-04,  ...,  7.2752e-02,\n",
       "            1.4967e-01,  1.9428e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.1533e-01, -9.6979e-02, -2.8492e-02,  ...,  9.7934e-03,\n",
       "           -7.2704e-02,  4.2504e-02]],\n",
       "\n",
       "         [[-9.3216e-02, -1.5313e-01, -7.4550e-02,  ...,  5.9874e-02,\n",
       "           -2.6313e-02,  3.4397e-01]],\n",
       "\n",
       "         [[ 1.0297e-01,  5.2828e-02,  2.3151e-01,  ...,  2.2125e-02,\n",
       "           -1.2867e-01,  3.0936e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 5.8546e-02, -1.3710e-02, -1.9255e-01,  ...,  4.8425e-02,\n",
       "           -8.8405e-02,  5.4689e-02]],\n",
       "\n",
       "         [[-1.3192e-01,  8.8368e-02, -1.4156e-01,  ..., -1.5053e-01,\n",
       "           -3.6285e-02,  1.3985e-01]],\n",
       "\n",
       "         [[ 3.4798e-02, -2.0436e-02,  2.9200e-02,  ..., -8.3135e-02,\n",
       "            6.5053e-03, -9.5515e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-7.1736e-02, -8.9937e-02, -8.4593e-02,  ..., -2.5837e-02,\n",
       "           -2.4385e-02, -4.2717e-02]],\n",
       "\n",
       "         [[-6.5155e-02, -2.7794e-01, -1.8503e-01,  ...,  1.0515e-01,\n",
       "           -8.9068e-02,  8.0077e-02]],\n",
       "\n",
       "         [[-6.7781e-02,  1.0529e-01, -1.4259e-01,  ...,  3.5550e-02,\n",
       "            4.3580e-02, -2.5840e-01]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:26:52.980414Z",
     "start_time": "2024-10-10T12:26:52.949161Z"
    }
   },
   "cell_type": "code",
   "source": "pooled_output",
   "id": "5744f99c6d070200",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1690, -0.0028, -0.0676,  ..., -0.0259,  0.0784,  0.0794],\n",
       "        [-0.1619,  0.1977, -0.1895,  ..., -0.0112, -0.2003,  0.0325]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "25468e876865fac2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:27:01.530492200Z",
     "start_time": "2024-10-10T07:15:19.087019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x1 = torch.rand(1, 14, 14, 224)\n",
    "x2 = torch.rand(1, 14, 14, 512)"
   ],
   "id": "308d3d70bd1556a4",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:27:01.530492200Z",
     "start_time": "2024-10-10T07:15:19.394732Z"
    }
   },
   "cell_type": "code",
   "source": "(att(x1, x2)).shape",
   "id": "63d35b52a43ce873",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 14, 128])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:27:01.530492200Z",
     "start_time": "2024-10-10T07:15:19.710140Z"
    }
   },
   "cell_type": "code",
   "source": "ClassifierHead(in_features=14, num_classes=2)(att(x1, x2))",
   "id": "b5dbbe5e2b5de8cd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1777,  0.0030]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:27:01.530492200Z",
     "start_time": "2024-10-10T07:15:22.352134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tem = torch.rand(1, 2, 10)\n",
    "torch.nn.Softmax(dim=1)(tem)"
   ],
   "id": "10ebb48943eb454b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5063, 0.4341, 0.5391, 0.3359, 0.4139, 0.5473, 0.4205, 0.4878,\n",
       "          0.5356, 0.4875],\n",
       "         [0.4937, 0.5659, 0.4609, 0.6641, 0.5861, 0.4527, 0.5795, 0.5122,\n",
       "          0.4644, 0.5125]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:27:01.530492200Z",
     "start_time": "2024-10-10T09:59:25.234262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(CNN, self).__init__()\n",
    "        self.module = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.GELU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=1, padding=1),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.GELU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2, padding=1),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.GELU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=1),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.GELU(),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.module(x)\n",
    "\n",
    "\n",
    "CNN(3)(image).shape"
   ],
   "id": "2ca855730e86a713",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 112, 112])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T10:27:01.530492200Z",
     "start_time": "2024-10-10T07:26:00.112386Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2d89fc2c24f67eae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 109, 109])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
